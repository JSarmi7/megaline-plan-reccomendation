{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   calls  minutes  messages   mb_used  is_ultra\n",
      "0   40.0   311.90      83.0  19915.42         0\n",
      "1   85.0   516.75      56.0  22696.96         0\n",
      "2   77.0   467.66      86.0  21060.45         0\n",
      "3  106.0   745.53      81.0   8437.39         1\n",
      "4   66.0   418.74       1.0  14502.75         0\n",
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n",
      "None\n",
      "\n",
      "Summary Statistics:\n",
      "             calls      minutes     messages       mb_used     is_ultra\n",
      "count  3214.000000  3214.000000  3214.000000   3214.000000  3214.000000\n",
      "mean     63.038892   438.208787    38.281269  17207.673836     0.306472\n",
      "std      33.236368   234.569872    36.148326   7570.968246     0.461100\n",
      "min       0.000000     0.000000     0.000000      0.000000     0.000000\n",
      "25%      40.000000   274.575000     9.000000  12491.902500     0.000000\n",
      "50%      62.000000   430.600000    30.000000  16943.235000     0.000000\n",
      "75%      82.000000   571.927500    57.000000  21424.700000     1.000000\n",
      "max     244.000000  1632.060000   224.000000  49745.730000     1.000000\n",
      "\n",
      "Missing Values:\n",
      "calls       0\n",
      "minutes     0\n",
      "messages    0\n",
      "mb_used     0\n",
      "is_ultra    0\n",
      "dtype: int64\n",
      "\n",
      "Target Distribution (is_ultra):\n",
      "0    0.693528\n",
      "1    0.306472\n",
      "Name: is_ultra, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/datasets/users_behavior.csv')\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nDataset Info:\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(df.describe())\n",
    "\n",
    "print(\"\\nMissing Values:\")\n",
    "print(df.isna().sum())\n",
    "\n",
    "print(\"\\nTarget Distribution (is_ultra):\")\n",
    "print(df['is_ultra'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split the data so that the ratio of smart and ultra is preserved in all sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 1928\n",
      "Validation set size: 643\n",
      "Test set size: 643\n",
      "\n",
      "Train target distribution:\n",
      " 0    0.693465\n",
      "1    0.306535\n",
      "Name: is_ultra, dtype: float64\n",
      "\n",
      "Validation target distribution:\n",
      " 0    0.693624\n",
      "1    0.306376\n",
      "Name: is_ultra, dtype: float64\n",
      "\n",
      "Test target distribution:\n",
      " 0    0.693624\n",
      "1    0.306376\n",
      "Name: is_ultra, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Features and target\n",
    "X = df.drop(columns=['is_ultra'])\n",
    "y = df['is_ultra']\n",
    "\n",
    "# First split: train+validation vs test\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=12345, stratify=y\n",
    ")\n",
    "\n",
    "# Second split: train vs validation\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_val, y_train_val, test_size=0.25, random_state=12345, stratify=y_train_val\n",
    ") \n",
    "# Note: 0.25 of the remaining 80% = 20%, so train=60%, valid=20%, test=20%\n",
    "\n",
    "# Verify split sizes\n",
    "print(\"Train set size:\", X_train.shape[0])\n",
    "print(\"Validation set size:\", X_valid.shape[0])\n",
    "print(\"Test set size:\", X_test.shape[0])\n",
    "\n",
    "# Check class balance in each set\n",
    "print(\"\\nTrain target distribution:\\n\", y_train.value_counts(normalize=True))\n",
    "print(\"\\nValidation target distribution:\\n\", y_valid.value_counts(normalize=True))\n",
    "print(\"\\nTest target distribution:\\n\", y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training multiple models to test to see which one performs best on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree validation accuracy: 0.7481\n",
      "Random Forest validation accuracy: 0.8134\n",
      "Logistic Regression validation accuracy: 0.7045\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# --- Decision Tree ---\n",
    "dt_model = DecisionTreeClassifier(random_state=12345)\n",
    "dt_model.fit(X_train, y_train)\n",
    "dt_valid_pred = dt_model.predict(X_valid)\n",
    "dt_valid_acc = accuracy_score(y_valid, dt_valid_pred)\n",
    "\n",
    "# --- Random Forest ---\n",
    "rf_model = RandomForestClassifier(random_state=12345)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_valid_pred = rf_model.predict(X_valid)\n",
    "rf_valid_acc = accuracy_score(y_valid, rf_valid_pred)\n",
    "\n",
    "# --- Logistic Regression ---\n",
    "lr_model = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_valid_pred = lr_model.predict(X_valid)\n",
    "lr_valid_acc = accuracy_score(y_valid, lr_valid_pred)\n",
    "\n",
    "# Print results\n",
    "print(f\"Decision Tree validation accuracy: {dt_valid_acc:.4f}\")\n",
    "print(f\"Random Forest validation accuracy: {rf_valid_acc:.4f}\")\n",
    "print(f\"Logistic Regression validation accuracy: {lr_valid_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tune decision tree and random forest and compare each to see which is best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Decision Tree: depth=5, acc=0.8165\n",
      "Best Random Forest: depth=8, n_estimators=10, acc=0.8320\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree tuning \n",
    "best_dt_acc = 0\n",
    "best_dt_depth = None\n",
    "for depth in range(1, 16):\n",
    "    model = DecisionTreeClassifier(max_depth=depth, random_state=12345)\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_valid)\n",
    "    acc = accuracy_score(y_valid, pred)\n",
    "    if acc > best_dt_acc:\n",
    "        best_dt_acc = acc\n",
    "        best_dt_depth = depth\n",
    "print(f\"Best Decision Tree: depth={best_dt_depth}, acc={best_dt_acc:.4f}\")\n",
    "\n",
    "# Random Forest tuning \n",
    "best_rf_acc = 0\n",
    "best_rf_params = (None, None)\n",
    "for depth in range(2, 11):\n",
    "    for n in [10, 50, 100, 200]:\n",
    "        model = RandomForestClassifier(max_depth=depth, n_estimators=n, random_state=12345)\n",
    "        model.fit(X_train, y_train)\n",
    "        pred = model.predict(X_valid)\n",
    "        acc = accuracy_score(y_valid, pred)\n",
    "        if acc > best_rf_acc:\n",
    "            best_rf_acc = acc\n",
    "            best_rf_params = (depth, n)\n",
    "print(f\"Best Random Forest: depth={best_rf_params[0]}, n_estimators={best_rf_params[1]}, acc={best_rf_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "random forest is the best as it has a higher validation score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Random Forest Test Accuracy: 0.8149\n"
     ]
    }
   ],
   "source": [
    "# Combine train and validation sets\n",
    "X_train_full = pd.concat([X_train, X_valid])\n",
    "y_train_full = pd.concat([y_train, y_valid])\n",
    "\n",
    "# Train best model on full training data\n",
    "final_model = RandomForestClassifier(\n",
    "    max_depth=8,\n",
    "    n_estimators=10,\n",
    "    random_state=12345\n",
    ")\n",
    "final_model.fit(X_train_full, y_train_full)\n",
    "\n",
    "# Evaluate on test set\n",
    "test_pred = final_model.predict(X_test)\n",
    "test_acc = accuracy_score(y_test, test_pred)\n",
    "\n",
    "print(f\"Final Random Forest Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "above 0.75 threshold and just a bit below our validation accuracy(0.8320). generalizes well and isnt overfitting much."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy (majority class): 0.6936\n",
      "\n",
      "Sample predictions vs actual:\n",
      "   Actual  Predicted\n",
      "0       0          0\n",
      "1       0          0\n",
      "2       1          1\n",
      "3       0          0\n",
      "4       0          0\n",
      "5       0          0\n",
      "6       0          0\n",
      "7       0          0\n",
      "8       0          0\n",
      "9       0          0\n"
     ]
    }
   ],
   "source": [
    "# 1. Baseline accuracy\n",
    "baseline_acc = y_test.value_counts(normalize=True).max()\n",
    "print(f\"Baseline accuracy (majority class): {baseline_acc:.4f}\")\n",
    "\n",
    "# 2. Sample predictions\n",
    "sample_results = pd.DataFrame({\n",
    "    'Actual': y_test[:10].values,\n",
    "    'Predicted': test_pred[:10]\n",
    "})\n",
    "print(\"\\nSample predictions vs actual:\")\n",
    "print(sample_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predictions mostly match the acutals in the small sample shown.. model correctly classified both classes not just the majority"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the project goal was to predict if a customer was going to choose the smart or ultra plan.\n",
    "the best model was as random forest(max_depth=8, n_estimators=10)\n",
    "validation accuracy = 0.8320\n",
    "test accuracy = 0.8149(above 0.75)\n",
    "baseline accuracy = 0.6936(major improvement to 0.8149)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
